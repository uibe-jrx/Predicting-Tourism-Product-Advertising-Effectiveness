{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98242ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"\"\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"\"\n",
    "\n",
    "INPUT_PRICE = 2 / 1_000_000\n",
    "OUTPUT_PRICE = 8 / 1_000_000\n",
    "\n",
    "JUDGE_PROMPT_TEMPLATE = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "def call_judge_llm(keyword, category, max_retries=3):\n",
    "    keyword = keyword.strip()\n",
    "    if not keyword:\n",
    "        return \"å¦\", None\n",
    "\n",
    "    system_message = {\"role\": \"system\", \"content\": JUDGE_PROMPT_TEMPLATE.format(keyword=keyword, category=category)}\n",
    "    user_message = {\"role\": \"user\", \"content\": f\"è¯·åˆ¤æ–­å…³é”®è¯â€œ{keyword}â€æ˜¯å¦å±äºâ€œ{category}â€ã€‚\"}\n",
    "\n",
    "    messages = [system_message, user_message]\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=messages,\n",
    "            )\n",
    "            usage = completion.usage\n",
    "            answer = completion.choices[0].message.content.strip()\n",
    "\n",
    "            if \"æ˜¯\" in answer and \"å¦\" not in answer:\n",
    "                return \"æ˜¯\", usage\n",
    "            elif \"å¦\" in answer:\n",
    "                return \"å¦\", usage\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "\n",
    "        except Exception:\n",
    "            time.sleep(min(2 ** attempt, 10) * random.uniform(0.8, 1.2))\n",
    "\n",
    "    return \"å¦\", None\n",
    "\n",
    "\n",
    "def judge_keywords(df, max_workers=10):\n",
    "    categories = [\"è§†è§‰å…³é”®è¯\", \"å¬è§‰å…³é”®è¯\", \"å—…è§‰å…³é”®è¯\", \"å‘³è§‰å…³é”®è¯\", \"è§¦è§‰å…³é”®è¯\"]\n",
    "    total_prompt_tokens = 0\n",
    "    total_completion_tokens = 0\n",
    "\n",
    "    keywords_with_category = []\n",
    "    for _, row in df.iterrows():\n",
    "        for cat in categories:\n",
    "            original_text = row.get(cat, \"\")\n",
    "            if not original_text or pd.isna(original_text):\n",
    "                continue\n",
    "            keywords = [kw.strip() for kw in original_text.split(\"ã€\") if kw.strip()]\n",
    "            for kw in keywords:\n",
    "                keywords_with_category.append((kw, cat))\n",
    "\n",
    "    keywords_with_category = list(set(keywords_with_category))\n",
    "\n",
    "    def task(keyword_cat):\n",
    "        kw, cat = keyword_cat\n",
    "        res, usage = call_judge_llm(kw, cat)\n",
    "        p_tokens = getattr(usage, \"prompt_tokens\", 0) if usage else 0\n",
    "        c_tokens = getattr(usage, \"completion_tokens\", 0) if usage else 0\n",
    "        return kw, cat, res, p_tokens, c_tokens\n",
    "\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(task, kc): kc for kc in keywords_with_category}\n",
    "        for future in as_completed(futures):\n",
    "            kw, cat = futures[future]\n",
    "            try:\n",
    "                k, c, res, p, co = future.result()\n",
    "                results[(k, c)] = res\n",
    "                total_prompt_tokens += p\n",
    "                total_completion_tokens += co\n",
    "            except Exception:\n",
    "                results[(kw, cat)] = \"å¦\"\n",
    "\n",
    "    new_columns = {cat: [] for cat in categories}\n",
    "    deleted_words_col = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        deleted_words = []\n",
    "        for cat in categories:\n",
    "            original_text = row.get(cat, \"\")\n",
    "            if not original_text or pd.isna(original_text):\n",
    "                new_columns[cat].append(\"\")\n",
    "                continue\n",
    "\n",
    "            keywords = [kw.strip() for kw in original_text.split(\"ã€\") if kw.strip()]\n",
    "            kept_keywords = []\n",
    "            for kw in keywords:\n",
    "                final_result = results.get((kw, cat), \"å¦\")\n",
    "                if final_result == \"æ˜¯\":\n",
    "                    kept_keywords.append(kw)\n",
    "                else:\n",
    "                    deleted_words.append(f\"{kw}ï¼ˆ{cat}ï¼‰\")\n",
    "\n",
    "            new_columns[cat].append(\"ã€\".join(kept_keywords))\n",
    "\n",
    "        deleted_words_col.append(\"ã€\".join(deleted_words))\n",
    "\n",
    "    for cat in categories:\n",
    "        df[cat] = new_columns[cat]\n",
    "    df[\"åˆ é™¤è¯ï¼ˆå«åŸæ„Ÿå®˜ç»´åº¦ï¼‰\"] = deleted_words_col\n",
    "\n",
    "    return df, total_prompt_tokens, total_completion_tokens\n",
    "\n",
    "\n",
    "def process_judge_excel(input_excel_path, output_excel_path):\n",
    "    df = pd.read_excel(input_excel_path, dtype=str)\n",
    "    df.fillna(\"\", inplace=True)\n",
    "\n",
    "    df_judged, prompt_tokens, completion_tokens = judge_keywords(df)\n",
    "    df_judged.to_excel(output_excel_path, index=False)\n",
    "\n",
    "    print(f\"âœ… åˆ¤å®šå¹¶ä¿å­˜å®Œæˆï¼š{output_excel_path}\")\n",
    "    return prompt_tokens, completion_tokens, os.path.basename(input_excel_path)\n",
    "\n",
    "\n",
    "def process_all_excels_judge(input_folder, output_folder):\n",
    "    excel_files = [os.path.join(root, f)\n",
    "                   for root, _, files in os.walk(input_folder)\n",
    "                   for f in files if f.lower().endswith(\".xlsx\")]\n",
    "    print(f\"å…±å‘ç° {len(excel_files)} ä¸ªexcelæ–‡ä»¶å¾…å¤„ç†åˆ¤å®š\\n\")\n",
    "\n",
    "    total_prompt_tokens = 0\n",
    "    total_completion_tokens = 0\n",
    "    file_stats = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    elapsed_times = []\n",
    "\n",
    "    for idx, excel_path in enumerate(excel_files, 1):\n",
    "        file_start = time.time()\n",
    "\n",
    "        print(f\"[{idx}/{len(excel_files)}] æ­£åœ¨å¤„ç†ï¼š{excel_path}\")\n",
    "        rel_path = os.path.relpath(excel_path, input_folder)\n",
    "        out_path = os.path.join(output_folder, rel_path)\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "        p_tokens, c_tokens, filename = process_judge_excel(excel_path, out_path)\n",
    "\n",
    "        input_cost = p_tokens * INPUT_PRICE\n",
    "        output_cost = c_tokens * OUTPUT_PRICE\n",
    "        total_cost = input_cost + output_cost\n",
    "\n",
    "        total_prompt_tokens += p_tokens\n",
    "        total_completion_tokens += c_tokens\n",
    "\n",
    "        elapsed = time.time() - file_start\n",
    "        elapsed_times.append(elapsed)\n",
    "\n",
    "        print(f\"ğŸ“ {filename} Tokenæ¶ˆè€—ï¼šè¾“å…¥ {p_tokens}ï¼Œè¾“å‡º {c_tokens}\")\n",
    "        print(f\"ğŸ’° æˆæœ¬ï¼šè¾“å…¥ {input_cost:.6f} å…ƒ + è¾“å‡º {output_cost:.6f} å…ƒ = åˆè®¡ {total_cost:.6f} å…ƒ\")\n",
    "\n",
    "        if idx < len(excel_files):\n",
    "            avg_time = sum(elapsed_times) / len(elapsed_times)\n",
    "            remaining_files = len(excel_files) - idx\n",
    "            est_remaining_time = avg_time * remaining_files / 60\n",
    "            print(f\"â³ é¢„è®¡å‰©ä½™å¤„ç†æ—¶é—´çº¦ {est_remaining_time:.1f} åˆ†é’Ÿ\\n\")\n",
    "\n",
    "        file_stats.append((filename, p_tokens, c_tokens, input_cost, output_cost, total_cost))\n",
    "\n",
    "    print(\"\\nâœ… åˆ¤å®šé˜¶æ®µå…¨éƒ¨å®Œæˆ\\n\")\n",
    "\n",
    "    print(\"ğŸ“Š æ¯ä¸ªæ–‡ä»¶è¯¦ç»†Tokenæ¶ˆè€—ä¸æˆæœ¬ï¼š\")\n",
    "    for f, p, c, ci, co, ct in file_stats:\n",
    "        print(f\"ğŸ“„ {f:30} | è¾“å…¥: {p:<7} | è¾“å‡º: {c:<7} | æˆæœ¬: {ct:.6f} å…ƒ\")\n",
    "\n",
    "    total_input_cost = total_prompt_tokens * INPUT_PRICE\n",
    "    total_output_cost = total_completion_tokens * OUTPUT_PRICE\n",
    "    total_cost = total_input_cost + total_output_cost\n",
    "\n",
    "    total_elapsed = time.time() - start_time\n",
    "    print(f\"\\nğŸ“ˆ æ€»Tokenæ¶ˆè€—ï¼šè¾“å…¥ {total_prompt_tokens}ï¼Œè¾“å‡º {total_completion_tokens}\")\n",
    "    print(f\"ğŸ’° æ€»æˆæœ¬ï¼šè¾“å…¥ {total_input_cost:.6f} å…ƒ + è¾“å‡º {total_output_cost:.6f} å…ƒ = åˆè®¡ {total_cost:.6f} å…ƒ\")\n",
    "    print(f\"ğŸ•’ å®é™…æ€»è€—æ—¶ï¼š{total_elapsed / 60:.1f} åˆ†é’Ÿ\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = r\"\"\n",
    "    output_folder = r\"\"\n",
    "    process_all_excels_judge(input_folder, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MYPAPPER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
